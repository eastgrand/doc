#!/usr/bin/env python3
"""
Upload Comprehensive Endpoints to Blob Storage
Upload the 26 comprehensive endpoints generated by the automation pipeline
"""

import os
import sys
from pathlib import Path

# Add the current directory to Python path
sys.path.append(str(Path(__file__).parent))

from blob_uploader import BlobUploader

def main():
    """Upload all 26 comprehensive endpoints to blob storage"""
    print("üöÄ Uploading Comprehensive Endpoints to Blob Storage")
    print("=" * 60)
    
    # Initialize blob uploader for HRB project
    project_root = Path("/Users/voldeck/code/mpiq-ai-chat")
    uploader = BlobUploader(project_root, project_prefix="hrb")
    
    # Check for blob token
    if not uploader.blob_token:
        print("‚ùå BLOB_READ_WRITE_TOKEN environment variable not found")
        print("üí° Set it in your .env.local file:")
        print("   BLOB_READ_WRITE_TOKEN=your_token_here")
        return 1
    
    # Define the 26 comprehensive endpoints we want to upload
    comprehensive_endpoints = [
        # Standard 19 endpoints  
        "strategic-analysis", "competitive-analysis", "demographic-insights",
        "correlation-analysis", "predictive-modeling", "trend-analysis",
        "scenario-analysis", "segment-profiling", "feature-importance-ranking",
        "feature-interactions", "outlier-detection", "spatial-clusters",
        "sensitivity-analysis", "model-performance", "anomaly-detection",
        "comparative-analysis", "brand-difference", "analyze", "customer-profile",
        
        # New 7 comprehensive model endpoints
        "algorithm-comparison", "ensemble-analysis", "model-selection",
        "anomaly-insights", "consensus-analysis", "dimensionality-insights"
    ]
    
    # Check which endpoints exist
    automation_dir = project_root / "scripts" / "automation"
    existing_endpoints = []
    
    for endpoint in comprehensive_endpoints:
        endpoint_file = automation_dir / f"{endpoint}.json"
        if endpoint_file.exists():
            existing_endpoints.append(endpoint)
        else:
            print(f"‚ö†Ô∏è  Endpoint file not found: {endpoint}.json")
    
    if not existing_endpoints:
        print("‚ùå No endpoint files found to upload")
        return 1
    
    print(f"üìÅ Found {len(existing_endpoints)} endpoint files to upload")
    print(f"üì§ Uploading from: {automation_dir}")
    
    # Upload the endpoints
    successful, failed = uploader.upload_from_directory(
        automation_dir, 
        existing_endpoints,
        force_reupload=False  # Only upload new/changed endpoints
    )
    
    # Print detailed summary
    print("\n" + uploader.generate_upload_summary())
    
    # Final status
    if failed == 0:
        print("üéâ All endpoints successfully uploaded to blob storage!")
        print("‚úÖ Client applications will now automatically use blob URLs for large files")
    else:
        print(f"‚ö†Ô∏è  {failed} endpoints failed to upload, but {successful} succeeded")
        print("üí° Failed endpoints are still available locally")
    
    return 0 if failed == 0 else 1

if __name__ == "__main__":
    exit(main())